---
title: "Validación de Cruce: Viajes y Etapas"
format: html
---

## 1. Setup y Carga de Datos

En este bloque, importamos librerías, definimos la conexión a GCS y las funciones para cargar datos y generar claves, asegurando que el notebook sea autocontenido.

```{python}
#| echo: false
import polars as pl
import os
import sys
import gcsfs
import pyarrow.dataset as ds
import pyarrow.fs as pafs
import re
from datetime import datetime

# Configuraciones de visualización
pl.Config.set_tbl_rows(20)
pl.Config.set_tbl_cols(50)

# --- Setup de Conexión y Funciones ---
GCS_BUCKET = os.getenv("GCS_BUCKET", "tesis-vonetto-datalake")
BRONZE_PREFIX = os.getenv("BRONZE_PREFIX", "lake/bronze")
gfs = gcsfs.GCSFileSystem(token="google_default")
fs_arrow = pafs.PyFileSystem(pafs.FSSpecHandler(gfs))

def gsjoin(*parts: str) -> str:
    return "gs://" + "/".join(s.strip("/") for s in parts)

def scan_bronze(dataset: str, semana_iso: str | None = None) -> pl.LazyFrame:
    base_gs = gsjoin(GCS_BUCKET, BRONZE_PREFIX, dataset).rstrip("/")
    if semana_iso:
        part_norm  = f"{base_gs}/semana_iso={semana_iso}/*.parquet"
        part_tuple = f"{base_gs}/semana_iso=('{semana_iso}',)/*.parquet"
        try:
            return pl.scan_parquet(part_norm)
        except Exception:
            try:
                return pl.scan_parquet(part_tuple)
            except Exception as e:
                raise e
    else:
        base_no_scheme = base_gs.replace("gs://", "", 1)
        dset = ds.dataset(base_no_scheme, filesystem=fs_arrow, format="parquet")
        return pl.scan_pyarrow_dataset(dset)

def _fix_ddmmyy_to_iso(expr: pl.Expr) -> pl.Expr:
    s = expr.cast(pl.Utf8).str.strip_chars()
    s = s.str.replace_all(r"^(\d{2})[-/](\d{2})[-/](\d{2})", r"20$3-$2-$1")
    s = s.str.replace_all(r"^(\d{2})[-/](\d{2})[-/](\d{4})", r"$3-$2-$1")
    s = s.str.replace_all(r"\s+", " ")
    s = s.str.replace_all(r"(\d{4}-\d{2}-\d{2}) (\d):(\d{2})", r"$1 0$2:$3")
    formats = ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M", "%Y-%m-%dT%H:%M:%S", "%Y-%m-%dT%H:%M", "%Y-%m-%d"]
    tries = [s.str.strptime(pl.Datetime, format=f, strict=False, exact=False) for f in formats]
    return pl.coalesce(tries)

def _norm_ts_min(expr: pl.Expr) -> pl.Expr:
    dt = _fix_ddmmyy_to_iso(expr)
    return dt.dt.strftime("%Y-%m-%d %H:%M")

def add_pks_viajes(lf: pl.LazyFrame) -> pl.LazyFrame:
    ts_any = pl.coalesce([pl.col("tiempo_inicio_viaje"), pl.col("tiempo_subida_1")])
    ts_min = _norm_ts_min(ts_any).alias("ts_inicio_min")
    return (lf.with_columns(ts_min)
              .with_columns(pl.struct([
                    pl.col("id_tarjeta").cast(pl.Utf8, strict=False),
                    pl.col("id_viaje").cast(pl.Int64, strict=False),
                    pl.col("ts_inicio_min")
                ]).hash(seed=0).alias("pk_viaje")))

def add_pks_etapas(lf: pl.LazyFrame) -> pl.LazyFrame:
    ts_any = pl.coalesce([pl.col("tiempo_subida"), pl.col("tiempo_bajada")])
    ts_min = _norm_ts_min(ts_any).alias("ts_subida_min")
    return (lf.with_columns(ts_min)
              .with_columns(pl.struct([
                    pl.col("id_tarjeta").cast(pl.Utf8, strict=False),
                    pl.col("id_viaje").cast(pl.Int64, strict=False),
                    pl.col("n_etapa").cast(pl.Int16, strict=False),
                    pl.col("ts_subida_min")
                ]).hash(seed=0).alias("pk_etapa")))

print("Setup completo.")
```

## 2. Diagnóstico de Pérdida

Aquí ejecutamos el análisis usando la estrategia de `left join` + `filter` para encontrar etapas huérfanas.

```{python}
SEMANA_ISO = "2025-W17"
lf_v = add_pks_viajes(scan_bronze("viajes", SEMANA_ISO))
lf_e = add_pks_etapas(scan_bronze("etapas", SEMANA_ISO))

lf_etapas_enriquecida = lf_e.with_columns(
    pl.min("ts_subida_min").over(["id_tarjeta", "id_viaje"]).alias("ts_inicio_viaje_reconstruido")
)

# ESTRATEGIA ALTERNATIVA: LEFT JOIN + FILTER
lf_joined = lf_etapas_enriquecida.join(
    lf_v.select(["id_tarjeta", "id_viaje", "ts_inicio_min", "pk_viaje"]),
    left_on=["id_tarjeta", "id_viaje", "ts_inicio_viaje_reconstruido"],
    right_on=["id_tarjeta", "id_viaje", "ts_inicio_min"],
    how="left"
)
etapas_perdidas = lf_joined.filter(pl.col("pk_viaje").is_null())

# --- Resultados ---
total_etapas = lf_e.select(pl.len()).collect(streaming=True).item()
n_etapas_perdidas = etapas_perdidas.select(pl.len()).collect(streaming=True).item()
pct_perdida = (n_etapas_perdidas / total_etapas) * 100 if total_etapas > 0 else 0

output_str = f"""--- Resultados del Diagnóstico (Estrategia: Left Join + Filter) ---
Semana analizada: {SEMANA_ISO}
Total de etapas: {total_etapas:,}
Etapas huérfanas (sin match en viajes): {n_etapas_perdidas:,}
Porcentaje de pérdida: {pct_perdida:.4f}%
"""
print(output_str)

```

## 3. Diagnóstico con Ventana de Tiempo (Fuzzy Join)

Ahora probamos la hipótesis de que las etapas huérfanas se deben a pequeñas discrepancias temporales. Usaremos un `join_asof` con una tolerancia de 5 minutos.

```{python}
# Para un join_asof, las tablas deben estar ordenadas por la clave de tiempo
# y las columnas de tiempo deben ser de tipo Datetime, no string.

# Convertimos las columnas de tiempo a Datetime
lf_v_dt = lf_v.with_columns(
    pl.col("ts_inicio_min").str.to_datetime("%Y-%m-%d %H:%M")
)
lf_e_dt = lf_etapas_enriquecida.with_columns(
    pl.col("ts_inicio_viaje_reconstruido").str.to_datetime("%Y-%m-%d %H:%M")
)

# Ordenamos por la clave de tiempo
lf_v_sorted = lf_v_dt.sort("ts_inicio_min")
lf_e_sorted = lf_e_dt.sort("ts_inicio_viaje_reconstruido")

# Realizamos el join_asof
fuzzy_joined = lf_e_sorted.join_asof(
    lf_v_sorted.select(["id_tarjeta", "id_viaje", "ts_inicio_min", "pk_viaje"]),
    left_on="ts_inicio_viaje_reconstruido",
    right_on="ts_inicio_min",
    by=["id_tarjeta", "id_viaje"],
    strategy="nearest", # Busca el viaje más cercano en el tiempo
    tolerance="5m"      # Ventana de 5 minutos hacia adelante y atrás
)

etapas_perdidas_fuzzy = fuzzy_joined.filter(pl.col("pk_viaje").is_null())

# --- Resultados con Ventana de Tiempo ---
n_etapas_perdidas_fuzzy = etapas_perdidas_fuzzy.select(pl.len()).collect(streaming=True).item()
pct_perdida_fuzzy = (n_etapas_perdidas_fuzzy / total_etapas) * 100 if total_etapas > 0 else 0

output_fuzzy_str = f"""--- Resultados del Diagnóstico (Estrategia: Fuzzy Join +/- 5 min) ---
Semana analizada: {SEMANA_ISO}
Total de etapas: {total_etapas:,}
Etapas huérfanas (con ventana de 5 min): {n_etapas_perdidas_fuzzy:,}
Porcentaje de pérdida: {pct_perdida_fuzzy:.4f}%
"""
print(output_fuzzy_str)

```
